{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formular Estimator\n",
    "\n",
    "The Formular Estimator is a powerful tool used in statistical analysis to estimate the relationship between variables. It is commonly used in regression analysis to determine the coefficients of a mathematical formula that best fits the data.\n",
    "In this Jupyter Notebook, we will explore the implementation of an easy example. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start by creating some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume, we don't know that this is a sine wave. We now roughly what we need, in this case we need a formula of third degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F:\n",
    "    a = np.random.randn()\n",
    "    b = np.random.randn()\n",
    "    c = np.random.randn()\n",
    "    d = np.random.randn()\n",
    "    learning_rate = 1e-6\n",
    "    losses = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.y_pred = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
    "        return self.y_pred\n",
    "\n",
    "    # Gradient descent\n",
    "    def backward(self, x, y, y_pred):\n",
    "        # We optimize the loss function with respect to a, b, c, d\n",
    "        self.losses.append(np.square(y_pred - y).sum())\n",
    "\n",
    "        # Compute the gradient\n",
    "        grad_y_pred = 2.0 * (y_pred - y)\n",
    "        grad_a = grad_y_pred.sum()\n",
    "        grad_b = (grad_y_pred * x).sum()\n",
    "        grad_c = (grad_y_pred * x ** 2).sum()\n",
    "        grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "        # Adjust the weight in the opposite direction of the gradient\n",
    "        # If our error increases in direction of the gradient, then we can reduce\n",
    "        # the error by going in the oppposite direction\n",
    "        self.a -= self.learning_rate * grad_a\n",
    "        self.b -= self.learning_rate * grad_b\n",
    "        self.c -= self.learning_rate * grad_c\n",
    "        self.d -= self.learning_rate * grad_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = F()\n",
    "plt.plot(net.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(2000):\n",
    "    y_pred = net.forward(x)\n",
    "    net.backward(x, y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1)\n",
    "axs[0].plot(net.forward(x))\n",
    "axs[1].plot(net.losses)\n",
    "print(f'Result: y = {net.a} + {net.b} x + {net.c} x^2 + {net.d} x^3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
