{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we will look a little bit at the theory behind neural networks. The relation between the learning of networks and probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n",
    "\n",
    "Neural networks model probability distributions: $P(y_i | \\theta)$. This function calculates the probability to sample y given the parameters $\\theta$.\n",
    "\n",
    "If you want to sample independent values from this distribution, e.g. calculate outputs using the network, we get $ P(y_0, y_1, ... | \\theta) = \\prod_i P(y_i|\\theta)$.\n",
    "\n",
    "In a neural network the $\\theta$ is represented by the weights. Improving the weights improves the model. This is called the Likelihood: $L(y_0, y_1, .. | \\theta) = P(y_0, y_1, .. | \\theta)$.\n",
    "\n",
    "Thus, the goal is to find the best parameters (weights) to achieve the best Likelihood:\n",
    "$$\\hat{\\theta}^{MLE}=\\underset{\\theta}{\\operatorname{argmax}} L(y_0, y_1, ..|\\theta) $$\n",
    "\n",
    "Combine the equations and you receive:\n",
    "\n",
    "$$ \\hat{\\theta}^{MLE}=\\underset{\\theta}{\\operatorname{argmax}} \\prod_i L(y_i|\\theta)$$\n",
    "\n",
    "Since multiplications are difficult to use, we rewrite the function to use sums:\n",
    "\n",
    "$$ \\hat{\\theta}^{MLE}=\\underset{\\theta}{\\operatorname{argmax}} \\sum_i \\operatorname{\\log} L(y_i|\\theta)$$\n",
    "\n",
    "Training a neural network means increasing the maximum log-likelihood!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Log-Likelihood\n",
    "\n",
    "If increasing the maximum log-likelihood is improving the network, so is decreasing the negative log-likelihood:\n",
    "\n",
    "Usually, this is called the loss function. It is calculated, by summing the logarithms over the correct classes:\n",
    "\n",
    "$$ NL(y_0, y_1, ..| \\theta) = - \\sum_i \\operatorname{\\log} L(y_i|\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Softmax:\n",
    "$$ S(y_i) = \\frac{e^y_i}{\\sum_{j=1}^n e^y_i}$$\n",
    "\n",
    "Let's assume our network has three classes: Boat, Dog and cat.\n",
    "\n",
    "The network has 3 output neurons and calculates for an input image the following:\n",
    "$$y_0 = 5$$\n",
    "$$y_1 = 2$$\n",
    "$$y_2 = 1$$\n",
    "\n",
    "If we apply softmax to the output of the network, we get:\n",
    "$$ S(y_0) = 0.93623955 $$\n",
    "$$ S(y_1) = 0.04661262 $$\n",
    "$$ S(y_2) = 0.01714783 $$\n",
    "\n",
    "where $\\sum S(y) = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(1,100)\n",
    "plt.plot(-np.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If in our example above our random sample is a boat, we get:\n",
    "\n",
    "$$ NL(S(y_0)) = -log(0.93623955) = 0.06.. $$\n",
    "\n",
    "If it would be a dog, we get:\n",
    "\n",
    "$$ NL(S(y_1)) = -log(0.04661262) = 3.06.. $$\n",
    "\n",
    "Wrong prediction have a high error. Thus if we minimize this function, we gradually improve our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
